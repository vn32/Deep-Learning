{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel:\n",
    "    \n",
    "    def __init__(self,learning_rate, n_iter, args):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.args = args\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def z_score(self,w,x,b):\n",
    "        return np.dot(w,x)+b\n",
    "    \n",
    "    def init_params(self,n_x):\n",
    "        parameters={}\n",
    "        n_a = n_x\n",
    "        for i in range(1,len(self.args)+1):\n",
    "            n_h = self.args[i-1][0]\n",
    "            parameters['w'+str(i)] = np.random.rand(n_h,n_a)*np.sqrt(1/n_x)\n",
    "            parameters['b'+str(i)] = np.random.randn(n_h,1)\n",
    "            n_a = n_h\n",
    "        return parameters\n",
    "    \n",
    "    def activation(self,z,fn = 'linear'):\n",
    "        act_fn ={'linear':z,\n",
    "                 'relu':np.maximum(z,0),\n",
    "                 'tanh':np.tanh(z),\n",
    "                 'sigmoid':1/(1+np.exp(-z)),\n",
    "                 'softmax':np.exp(z)/np.sum(np.exp(z))}\n",
    "        return act_fn[fn]\n",
    "    \n",
    "    def forward_prop(self,x, parameters):\n",
    "        L = len(args)\n",
    "        z_scores = {}\n",
    "        activations = {'a0':x}\n",
    "        for i in range(1,L+1):\n",
    "            z_scores['z'+str(i)] = self.z_score(parameters['w'+str(i)],activations['a'+str(i-1)],parameters['b'+str(i)])\n",
    "            z = z_scores['z'+str(i)]\n",
    "            activations['a'+str(i)] = self.activation(z,fn=self.args[i-1][1])\n",
    "        \n",
    "        return z_scores, activations\n",
    "    \n",
    "    def compute_cost(self,y,y_hat):\n",
    "        m = y.shape[0]\n",
    "        cost = (-1/m)*(np.dot(y, np.log(y_hat.T+0.0000001)) + np.dot(1-y, np.log(1-y_hat.T+0.0000001)))\n",
    "        return np.squeeze(cost)\n",
    "        \n",
    "    def backprop(self,y, parameters, z_scores, activations):\n",
    "        gradients = {}\n",
    "        L = len(self.args)\n",
    "        m = y.shape[0]\n",
    "        for i in range(L,0,-1):\n",
    "            if i==L:\n",
    "                gradients['dz'+str(i)]=activations['a'+str(i)]-y\n",
    "            else:\n",
    "                gradients['dz'+str(i)] = np.multiply(np.dot(parameters['w'+str(i+1)].T, gradients['dz'+str(i+1)]), 1*(z_scores['z'+str(i)]>=0))\n",
    "            dz = gradients['dz'+str(i)]\n",
    "            gradients['dw'+str(i)] = (1/m)*np.matmul(dz,activations['a'+str(i-1)].T)\n",
    "            gradients['db'+str(i)] = (1/m)*np.sum(dz,axis=1,keepdims=True)\n",
    "        return gradients\n",
    "    \n",
    "    def update_params(self,parameters, gradients):\n",
    "        eta = self.learning_rate\n",
    "        for i in range(1,len(parameters)//2+1):\n",
    "            parameters['w'+str(i)]-=eta*gradients['dw'+str(i)]\n",
    "            parameters['b'+str(i)]-=eta*gradients['db'+str(i)]\n",
    "        return parameters\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        np.random.seed(5)\n",
    "        params = self.init_params(x.shape[0])\n",
    "        for i in range(self.n_iter):\n",
    "            z_scores,activations = self.forward_prop(x,params)\n",
    "            y_hat = activations['a'+str(len(self.args))]\n",
    "            #print(y_hat)\n",
    "            cost = self.compute_cost(y,y_hat)\n",
    "            gradients = self.backprop(y,params,z_scores,activations)\n",
    "            params = self.update_params(params,gradients)\n",
    "            if i%1000==0:\n",
    "                print('Iteration : {}      Cost : {}'.format(i,cost))\n",
    "        return params\n",
    "    \n",
    "    def predict(self,x_test,params):\n",
    "        z_scores, activations = self.forward_prop(x_test,params)\n",
    "        y_pred = 1*(activations['a'+str(len(params)//2)]>0.5)\n",
    "        return np.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mrityunjay/Downloads/sonar.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.columns=['x'+str(i) for i in range(len(df.columns))]\n",
    "X=df.drop(['x60'],axis=1)\n",
    "Y=df['x60']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=1)\n",
    "\n",
    "X_train = np.transpose(X_train.values)\n",
    "X_test = np.transpose(X_test.values)\n",
    "\n",
    "Y_train = 1*(Y_train.values=='R')\n",
    "Y_test = 1*(Y_test.values=='R')\n",
    "Y_train = Y_train.reshape(1,Y_train.shape[0])\n",
    "Y_test = Y_test.reshape(1,Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0      Cost : 110.57895885689418\n",
      "Iteration : 1000      Cost : 97.20215085637494\n",
      "Iteration : 2000      Cost : 24.107818263784335\n",
      "Iteration : 3000      Cost : 0.059483096239265856\n",
      "Iteration : 4000      Cost : 0.01442973769956715\n",
      "Iteration : 5000      Cost : 0.007538193128651977\n",
      "Iteration : 6000      Cost : 0.004934892738423426\n",
      "Iteration : 7000      Cost : 0.00361163395157489\n",
      "Iteration : 8000      Cost : 0.002820134439769308\n",
      "Iteration : 9000      Cost : 0.0022975636960569958\n"
     ]
    }
   ],
   "source": [
    "args=[(100,'relu'),(50,'relu'),(10,'relu'),(5,'relu'),(3,'relu'),(1,'sigmoid')]\n",
    "nn = NNModel(learning_rate=0.001, n_iter = 10000, args=args)\n",
    "params = nn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1\n",
      " 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = nn.predict(X_test,params)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1\n",
      "  1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_pred,np.squeeze(Y_test))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
